trainer_args:
  max_epochs: 100
  log_every_n_steps: 10
dataloader_settings:
  num_workers: 4
  batch_size: 32
  persistent_workers: True
callbacks:
  - name: "EarlyStopping"
    params: 
      monitor: "val/loss_total_tarreg"
      mode: "min"
      min_delta: 1.0e-8
      patience: 20
      verbose: True
  - name: "ModelCheckpoint"
    params:
      save_top_k: 5
      monitor: "val/loss_total_tarreg"
      mode: "min"
      filename: "model-{epoch:02d}-{val/loss_total_tarreg:.3f}"
logger:
  save_dir: "./lightning_logs"
  name: "dragonnet_baseline"
  version: "lr_sgd5e-7"
optimizer_settings:
  name: "SGD"
  params:
    lr: 5.0e-7
    momentum: 0.9
    nesterov: True
scheduler_settings:
  name: "ReduceLROnPlateau"
  lightning_params:
    monitor: "val/loss_total_tarreg"
    frequency: 1
  params:
    factor: 0.5
    patience: 5
    mode: "min"
    verbose: True
    min_lr: 0.0
    cooldown: 0
    threshold: 0.0

  
