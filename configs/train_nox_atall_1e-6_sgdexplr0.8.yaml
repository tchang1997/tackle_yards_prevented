trainer_args:
  num_sanity_val_steps: 2
  max_epochs: 100
  log_every_n_steps: 10
dataloader_settings:
  num_workers: 2
  batch_size: 16
  persistent_workers: True
model_settings:
  representation_class: "SimplifiedMultiLevelTransformer"
  input_size:
    - 210
    - 5
  model_kwargs:
    geom_n_encoder_layers: 12
    ball_carrier_n_encoder_layers: 12
    player_embed_dim: 128
    geom_embed_dim: 256
    drop_absolute_x: True
    drop_absolute_x_from_all: True
    nonlinear_propensity_model: True
callbacks:
  - name: "EarlyStopping"
    params: 
      monitor: "val/loss_total_tarreg"
      mode: "min"
      min_delta: 1.0e-8
      patience: 10
      verbose: True
  - name: "ModelCheckpoint"
    params:
      save_top_k: 3
      monitor: "val/loss_total_tarreg"
      mode: "min"
      filename: "model-{epoch:02d}-{val/loss_total_tarreg:.3f}"
logger:
  save_dir: "./lightning_logs"
  name: "dragonnet_baseline"
  version: "train_nox_atall_sgd1e-6_wd1e-4_explr0.8"
optimizer_settings:
  name: "SGD"
  params:
    lr: 1.0e-6
    momentum: 0.9
    weight_decay: 1.0e-4
scheduler_settings:
  name: "ExponentialLR"
  params:
    gamma: 0.8
    verbose: True
